# Data Science Repository 
>*“The magic is in the work, in the effort, in the confidence and in the conviction that you can achieve anything you set your mind to.”*<br />
>Eliud Kipchoge

<br />This repository contains all projects completed during the [Data Science Bootcamp] HENRY. The goal is to provide resources and examples for future colleagues interested in learning and improving their data science skills.<br /> 

If you find this repository useful, support it by making "★ Star". Thank you, go ahead!!! <br />
<br />

## M4 - Data Engineer
[About_M4](M4/About_M4.md) - Key Module 4 Information.

#### Integrative Project - M4 | [Repository: DS-M4-Herramientas_Big_Data](https://github.com/JohannaRangel/DS-M4-Herramientas_Big_Data) 
**```Docker```** **```Spark```** **```Scala```** **```Hive```** **```HBase```** **```MongoDB```** **```Neo4J```** **```Zeppelin```** **```Kafka```**<br />

During this practice, the idea is to emulate a work environment. The innovation team has requested the construction of an MVP (Minimum Viable Product) for a Big Data environment. The goal is to load CSV files that were previously used in a data warehouse in MySQL into a Hadoop environment.<br />
The Infrastructure management is not entirely convinced about using this technology, so no budget has been allocated for this initiative. Consequently, it is currently not possible to use a vendor (Azure, AWS, Google) to implement this environment. That's why the entire MVP must be implemented using Docker, enabling a demonstration to the Infrastructure team to showcase the advantages of employing Big Data technologies. 
<br />


## M5 - Data Analytics
[About_M5](M5/About_M5.md) - Key Module 5 Information.

#### Integrative Project - M5 | [Proyecto Integrador - Airbnb](https://github.com/JohannaRangel/DataScience_SoyHenry/blob/main/M5/airbnb/Proyecto%20Integrador%20Airbnb.md) 
Contexto: During this practice, the idea is to emulate a work environment. The innovation team has requested the construction of an MVP (Minimum Viable Product) for a Big Data environment. The goal is to load CSV files that were previously used in a data warehouse in MySQL into a Hadoop environment.<br />
The Infrastructure management is not entirely convinced about using this technology, so no budget has been allocated for this initiative. Consequently, it is currently not possible to use a vendor (Azure, AWS, Google) to implement this environment. That's why the entire MVP must be implemented using Docker, enabling a demonstration to the Infrastructure team to showcase the advantages of employing Big Data technologies.

<br />


M6 - Machine Learning
------------- 
[About_M3](M3/About_M3.md) - Key Module 3 Information
1. [Homework_M3_1](M3/Homework_M3_1_VariablesFunctionsProcedures.sql) - Variables. Features. Stored Procedures
2. [Help](.ipynb) -  documentation
<br />


